{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUmijvzbJdaM"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"YOUR_API_KEY_HERE\"# REPLACE WITH YOUR KEY\n",
        "\"\n"
      ],
      "metadata": {
        "id": "HwMOhsNZKKA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Read the API key from environment\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# Create the model\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Send a prompt\n",
        "response = model.generate_content(\"Write a poem\")\n",
        "print(response.text)\n",
        "\n",
        "prompt = \"Write a short creative story about this pome who discovers emotions.\"\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)\n",
        "### introducing mutiple chats\n",
        "chat = model.start_chat(history=[])\n",
        "response = chat.send_message(\"What is the capital of France?\")\n",
        "print(\"Gemini:\", response.text)\n",
        "\n",
        "response = chat.send_message(\"And what is it famous for?\")\n",
        "print(\"Gemini:\", response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "y7OXoz9bKZ7A",
        "outputId": "e7ab7c56-39f4-4914-a58b-48a063927d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The wind whispers secrets through leaves of jade,\n",
            "A rustling chorus, a serenade.\n",
            "Sun dips low, painting clouds with fire,\n",
            "Igniting embers, a fading pyre.\n",
            "\n",
            "The day is done, its colours bleed,\n",
            "Into the twilight, a silent creed.\n",
            "Stars ignite, like diamonds strewn,\n",
            "Across the velvet, a midnight moon.\n",
            "\n",
            "A lonely owl, its haunting call,\n",
            "Echoes softly, encompassing all.\n",
            "The world is hushed, in slumber deep,\n",
            "While secrets whispered, the darkness keep.\n",
            "\n",
            "Pom, a pomegranate the size of a grapefruit, had always existed in a state of pleasant, unthinking redness. He sat nestled amongst his brethren, basking in the warm sun on the gnarled branch. Life, for Pom, was the rhythmic cycle of sun and shade, the occasional shake of the branch by a playful breeze. He'd never felt anything beyond a dull contentment.\n",
            "\n",
            "Then came the storm.\n",
            "\n",
            "Rain lashed against the leaves, a furious drumming that shook Pom to his very core. The wind howled, a terrifying shriek that echoed through his juicy segments. Fear, a brand new and terrifying sensation, clenched at his rind.  It wasn't the pleasant tightening of his skin in the sun, but a sharp, icy grip that left him trembling.\n",
            "\n",
            "He watched, helpless, as a lightning bolt struck a nearby tree, splintering it in two.  He felt a pang, not of physical pain, but something deeper, a profound sadness that echoed the splintering wood. It was a grief so intense, so alien, that it almost burst him open.\n",
            "\n",
            "When the storm passed, the world was washed clean, sparkling under the newly-risen sun.  The air smelled of petrichor, sharp and clean.  Pom, however, felt a strange mixture of emotions. Relief, so profound it made him want to burst with joy. Gratitude for his survival, mingled with sorrow for the fallen tree.\n",
            "\n",
            "He saw a small bird, its wing bruised and broken, hobbling across the ground.  And for the first time, Pom felt compassion. A gentle warmth bloomed within his ruby flesh, a feeling so powerful it made his skin tingle.  He wished, with a longing he‚Äôd never known existed, that he could somehow help the bird.\n",
            "\n",
            "From that day on, Pom was never the same.  He experienced the world with a newfound depth, a vibrant tapestry of joy and sorrow, fear and love, woven into the very fabric of his being. He was still a pomegranate, plump and red, but now he possessed a soul as rich and complex as the colours within him.  He was Pom, the feeling pomegranate, and his life, once a simple cycle, was now a breathtaking adventure.\n",
            "\n",
            "Gemini: Paris\n",
            "\n",
            "Gemini: Paris is famous for many things, including but not limited to:\n",
            "\n",
            "* **The Eiffel Tower:** An iconic wrought-iron lattice tower on the Champ de Mars.\n",
            "* **The Louvre Museum:** One of the world's largest and most renowned museums, housing masterpieces like the Mona Lisa.\n",
            "* **The Arc de Triomphe:** A triumphal arch commissioned by Napoleon.\n",
            "* **Notre Dame Cathedral:** A Gothic masterpiece (currently under reconstruction).\n",
            "* **The Seine River:** A river that flows through the heart of Paris, with many bridges and charming riverside walks.\n",
            "* **Its fashion:** Paris is a global center for haute couture and fashion design.\n",
            "* **Its art and culture:**  A rich history of art, literature, and philosophy, influencing global culture for centuries.\n",
            "* **Its romantic atmosphere:** Often considered one of the most romantic cities in the world.\n",
            "* **Its cuisine:**  Known for its exquisite restaurants and bakeries, offering a wide variety of culinary delights.\n",
            "* **Its architecture:**  A beautiful blend of architectural styles, from medieval to modern.\n",
            "\n",
            "\n",
            "This is just a brief overview; Paris's fame stems from a rich tapestry of history, culture, and iconic landmarks.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=#REPLACE WITH YOUR KEY IN \" HERE \")\n",
        "\n",
        "def chat_with_ai():\n",
        "    print(\"ü§ñ AI Chatbot ‚Äî type 'exit' to quit\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "            print(\"Chat ended.\")\n",
        "            break\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[{\"role\": \"user\", \"content\": user_input}]\n",
        "            )\n",
        "            print(\"AI:\", response.choices[0].message.content.strip())\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è Error:\", e)\n",
        "\n",
        "chat_with_ai()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QmdiG-9QCtN",
        "outputId": "cfbb4583-d047-4341-ab0f-356d2ba10cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ AI Chatbot ‚Äî type 'exit' to quit\n",
            "\n",
            "You: exit\n",
            "Chat ended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Play with Parameters Experiment ---\n",
        "generation_config = {\n",
        "    \"temperature\": 0.9,  # Higher = more creative, lower = more factual\n",
        "    \"top_p\": 1,          # Controls diversity via nucleus sampling\n",
        "    \"top_k\": 1,          # Controls diversity via top-k sampling\n",
        "    \"max_output_tokens\": 200  # Limit on length of output\n",
        "}\n",
        "\n",
        "# Optional: Safety filters to block harmful content\n",
        "safety_settings = [\n",
        "    {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_ONLY_HIGH\"},\n",
        "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_ONLY_HIGH\"},\n",
        "]\n",
        "\n",
        "# Test prompt\n",
        "prompt = \"Describe a futuristic city powered entirely by renewable energy.\"\n",
        "\n",
        "# Generate content using parameters\n",
        "response = model.generate_content(\n",
        "    prompt,\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings\n",
        ")\n",
        "\n",
        "# Show the result\n",
        "print(\"Response with tuned parameters:\")\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "YzbaPcmTeuhK",
        "outputId": "ef2e265a-7fd1-40cc-8b1f-82087b4099ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response with tuned parameters:\n",
            "Aetheria hummed, not with the roar of combustion engines, but with the gentle whir of wind turbines and the soft susurrus of solar panels absorbing the sun's energy.  Built on a sprawling archipelago, its buildings, crafted from bio-luminescent concrete and sustainable bamboo, rose from the turquoise waters like shimmering coral.  The city wasn't just powered by renewables, it was *integrated* with them.\n",
            "\n",
            "Towering wind farms, elegantly designed like colossal, graceful trees, dotted the outskirts, their blades capturing the consistent ocean breezes.  Submerged beneath the waves, arrays of tidal turbines harnessed the rhythmic power of the tides, their energy transmitted seamlessly through underwater cables.  The city‚Äôs rooftops, balconies, and even pavements were covered in photovoltaic cells, transforming sunlight into electricity with astonishing efficiency.  Algorithmic shading systems adjusted throughout the day, maximizing energy absorption while minimizing heat.\n",
            "\n",
            "Transportation was a symphony of silent movement.  Maglev trains whooshed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "import io\n",
        "for m in genai.list_models():\n",
        "    if \"generateContent\" in m.supported_generation_methods:\n",
        "        print(m.name)\n",
        "image_url = \"https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_272x92dp.png\"\n",
        "image_response = requests.get(image_url)\n",
        "img = Image.open(io.BytesIO(image_response.content))\n",
        "\n",
        "model_vision = genai.GenerativeModel('gemini-1.5-flash')\n",
        "prompt_and_image = [\"What is in this image?\", img]\n",
        "response_vision = model_vision.generate_content(prompt_and_image)\n",
        "print(response_vision.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "h6_7_Kh-VQ-5",
        "outputId": "6991417d-aab8-4f5b-9d77-c5c50015883c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-flash-lite-preview-06-17\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-2.5-flash-lite\n",
            "That's the Google logo.  It shows the word \"Google\" in its distinctive multi-colored lettering.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "Part 1: Chain-of-Thought (CoT) Prompting\n",
        "Objective: Guide the model through a step-by-step reasoning process to solve complex problems.\n",
        "HERE WE BEGINS OUR TASKS\n",
        "\n",
        "Task 1.1:\n",
        "Create a CoT prompt that asks the model to calculate the total cost of a road trip, including\n",
        "fuel, accommodation, and food expenses. Ensure the prompt instructs the model to break\n",
        "down the problem into manageable steps.\n",
        "Deliverable: A CoT prompt that results in a detailed cost calculation.\n"
      ],
      "metadata": {
        "id": "aMxKvheRMVkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# --- Set your API key here ---\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"**********\"  # Replace with your key\n",
        "\n",
        "# Configure the API\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# Create the model\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Your custom prompt\n",
        "prompt = \"\"\"Create a CoT prompt that asks the model to calculate the total cost of a road trip, including\n",
        "fuel, accommodation, and food expenses. Ensure the prompt instructs the model to break\n",
        "down the problem into manageable steps.\n",
        "Deliverable: A CoT prompt that results in a detailed cost calculation.\n",
        "\"\"\"\n",
        "\n",
        "# Send prompt to Gemini\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "# Print the result\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "vniDc0avLYL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.2:\n",
        "Develop a CoT prompt that asks the model to analyze the causes and effects of the French\n",
        "Revolution. The prompt should guide the model to discuss each cause and its subsequent\n",
        "impact in a logical sequence.\n",
        "Deliverable: A CoT prompt that elicits a thorough historical analysis.\n"
      ],
      "metadata": {
        "id": "ZOQPqXz7Mcfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# --- Set your API key here ---\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"**********\"  # Replace with your key\n",
        "\n",
        "# Configure the API\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# Create the model\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Your custom prompt\n",
        "prompt = \"\"\"\n",
        "Develop a CoT prompt that asks the model to analyze the causes and effects of the French\n",
        "Revolution. The prompt should guide the model to discuss each cause and its subsequent\n",
        "impact in a logical sequence.\n",
        "Deliverable: A CoT prompt that elicits a thorough historical analysis.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Send prompt to Gemini\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "# Print the result\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "RbzOMuJcMopB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2: Meta-Prompting\n",
        "Objective: Create or refine prompts to achieve specific goals using meta-level instructions.\n",
        "Task 2.1:\n",
        "Write a meta-prompt that instructs the model to generate a prompt for a debate on the pros\n",
        "and cons of renewable energy. The goal is to ensure that the generated prompt encourages\n",
        "a balanced and well-rounded discussion.\n",
        "Deliverable: A meta-prompt that leads to an effective debate prompt.\n"
      ],
      "metadata": {
        "id": "6kLLwelwNxId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# --- Set your API key here ---\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"**********\"  # Replace with your key\n",
        "\n",
        "# Configure the API\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# Create the model\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Your custom prompt\n",
        "prompt = \"\"\"Part 2: Meta-Prompting Objective: Create or refine prompts to achieve specific goals using meta-level instructions. Task 2.1: Write a meta-prompt that instructs the model to generate a prompt for a debate on the pros and cons of renewable energy. The goal is to ensure that the generated prompt encourages a balanced and well-rounded discussion. Deliverable: A meta-prompt that leads to an effective debate prompt.\n",
        "\"\"\"\n",
        "\n",
        "# Send prompt to Gemini\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "# Print the result\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "NWubtvSEOAKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2.2:\n",
        "Use meta-prompting to refine the following prompt: 'Describe the impact of technology on\n",
        "education.' Your goal is to make the prompt more specific and focused on recent\n",
        "advancements.\n",
        "Deliverable: A meta-prompt that refines the original prompt to focus on recent\n",
        "technological impacts.\n"
      ],
      "metadata": {
        "id": "JOvv-ogJO6Es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"**********\"  # Replace with your key\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "prompt = \"\"\"\n",
        "Use meta-prompting to refine the following prompt: 'Describe the impact of technology on\n",
        "education.' Your goal is to make the prompt more specific and focused on recent\n",
        "advancements.\n",
        "Deliverable: A meta-prompt that refines the original prompt to focus on recent\n",
        "technological impacts.\n",
        "\"\"\"\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "w2YgZMvSO7q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3: Question Refinement\n",
        "Objective: Improve the clarity, specificity, and effectiveness of questions to elicit better\n",
        "responses.\n",
        "Task 3.1:\n",
        "Take the question 'What are the benefits of exercise?' and refine it to focus on the benefits of\n",
        "exercise for mental health, targeting a college-aged audience.\n",
        "Deliverable: A refined question that prompts a detailed response on mental health benefits.\n"
      ],
      "metadata": {
        "id": "FUJkXUGtPWkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"**********\"  # Replace with your key\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "prompt = \"\"\"\n",
        "\n",
        "Task 3.1:\n",
        "Take the question 'What are the benefits of exercise?' and refine it to focus on the benefits of\n",
        "exercise for mental health, targeting a college-aged audience.\n",
        "Deliverable: A refined question that prompts a detailed response on mental health benefits.\n",
        "\n",
        "[AT LEAST 10 QUESTIONS]\n",
        "\n",
        "\"\"\"\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "73qesaQvPN93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3.2:\n",
        "Refine the question 'How can businesses improve their sustainability practices?' to make it\n",
        "more specific by focusing on small businesses in urban areas.\n",
        "Deliverable: A refined question that narrows the focus to small urban businesses.\n"
      ],
      "metadata": {
        "id": "eEmrQq9_hlts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"**********\"  # Replace with your key\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "prompt = \"\"\"\n",
        "\n",
        "Task 3.2:\n",
        "Refine the question 'How can businesses improve their sustainability practices?' to make it\n",
        "more specific by focusing on small businesses in urban areas.\n",
        "Deliverable: A refined question that narrows the focus to small urban businesses.\n",
        "[AT LEAST 10 QUESTIONS]\n",
        "\n",
        "\"\"\"\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "riTa6njKPqNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 4: Sandwich Prompting\n",
        "Objective: Structure prompts with clear instructions before and after the main content to\n",
        "guide the model effectively.\n",
        "Task 4.1:\n",
        "Create a sandwich prompt that asks the model to write a cover letter for a job application.\n",
        "The pre-prompt should provide context about the job, and the post-prompt should remind\n",
        "the model to include a call to action and ensure a professional tone.\n",
        "Deliverable: A sandwich prompt that results in a well-structured cover letter.\n"
      ],
      "metadata": {
        "id": "I2NfTZKhjRPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"**********\"  # Replace with your key\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "prompt = \"\"\"\n",
        "\n",
        "Create a sandwich prompt that asks the model to write a cover letter for a job application. The pre-prompt should provide context about the job, and the post-prompt should remind the model to include a call to action and ensure a professional tone. Deliverable: A sandwich prompt that results in a well-structured cover letter.\n",
        "\n",
        "\"\"\"\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "sNEVr2mVjRdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4.2:\n",
        "Develop a sandwich prompt for the model to summarize a research article. The pre-prompt\n",
        "should specify the importance of accuracy, and the post-prompt should remind the model to\n",
        "keep the summary within 200 words.\n",
        "Deliverable: A sandwich prompt that leads to a concise and accurate summary.\n"
      ],
      "metadata": {
        "id": "wR90E_KXkM5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# --- Set your API key here ---\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"**********\"  # Replace with your valid Gemini API key\n",
        "\n",
        "# Configure the API\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# Create the model\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Sample research article text\n",
        "article_text = \"\"\"\n",
        "Researchers at the University of GreenTech conducted a 12-month study on the efficiency of solar panels\n",
        "in varying climate conditions. The study analyzed over 500 panels across three different environments:\n",
        "tropical, temperate, and arid regions. Data showed that tropical regions had an average efficiency drop\n",
        "of 12% due to higher humidity, while arid regions maintained stable output but suffered from increased\n",
        "dust accumulation, lowering efficiency by 7%. Temperate climates demonstrated the highest year-round\n",
        "performance with only a 3% variation. The research concluded that location-specific maintenance strategies\n",
        "could improve long-term efficiency by up to 15%.\n",
        "\"\"\"\n",
        "\n",
        "# Build the sandwich prompt\n",
        "prompt = f\"\"\"**Pre-prompt:** The following research article requires a highly accurate and detailed summary.\n",
        "Inaccuracies will be detrimental to understanding the core findings. Please prioritize factual correctness above all else.\n",
        "Pay close attention to the study's methodology, key results, and conclusions.\n",
        "\n",
        "\n",
        "{article_text}\n",
        "\n",
        "**Post-prompt:** Provide an elaborate summary of the research article above in at least 10 lines.\n",
        "Clearly separate the points into distinct sentences or bullet points, covering background, methodology,\n",
        "data analysis, results, and conclusions. Avoid unnecessary detail but ensure completeness.\n",
        "\"\"\"\n",
        "\n",
        "# Send prompt to Gemini\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "# Print the result\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "id": "pTa0orvtkR3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a prompt using the Cognitive Verifier Pattern that asks the model to solve a logic puzzle.\n",
        "The prompt should include a final verification step where the model checks its own solution for consistency.\n",
        "Deliverable: A prompt that includes a cognitive verification step to ensure accuracy."
      ],
      "metadata": {
        "id": "aswRZJ_EnyNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# --- Set your API key here ---\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"A**********\"  # Replace with your valid Gemini API key\n",
        "\n",
        "# Configure the API\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# Create the model\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Your custom prompt\n",
        "prompt = \"\"\"Create a prompt using the Cognitive Verifier Pattern that asks the model to solve a logic puzzle.\n",
        "The prompt should include a final verification step where the model checks its own solution for consistency.\n",
        "Deliverable: A prompt that includes a cognitive verification step to ensure accuracy.\n",
        "\"\"\"\n",
        "\n",
        "# Send prompt to Gemini\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "# Print the result\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "id": "2dh67NcOmGWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.2:\n",
        "Develop a prompt where the model must provide a financial analysis, including a final\n",
        "verification step to check for any mathematical errors or inconsistencies in the output.\n",
        "Deliverable: A financial analysis prompt that incorporates cognitive verification.\n"
      ],
      "metadata": {
        "id": "Xkkq1OlUn8-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# --- Set your API key here ---\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"A**********\"  # Replace with your valid Gemini API key\n",
        "\n",
        "# Configure the API\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# Create the model\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Your custom prompt\n",
        "prompt = \"\"\"\n",
        "Develop a prompt where the model must provide a financial analysis, including a final\n",
        "verification step to check for any mathematical errors or inconsistencies in the output.\n",
        "Deliverable: A financial analysis prompt that incorporates cognitive verification.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Send prompt to Gemini\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "# Print the result\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "id": "ceKh4tCSn_0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Audience Persona Pattern\n",
        "Objective: Tailor prompts to generate responses that resonate with specific audience\n",
        "personas."
      ],
      "metadata": {
        "id": "wcnPqfrwoccL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"**********\"  # Replace with your key\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "prompt = \"\"\"\n",
        "\n",
        "Audience Persona Pattern\n",
        "Objective: Tailor prompts to generate responses that resonate with specific audience\n",
        "personas.\n",
        "\n",
        "\"\"\"\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "oTwiuDryofxi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}